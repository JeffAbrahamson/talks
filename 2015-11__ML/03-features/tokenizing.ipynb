{
 "metadata": {
  "name": "",
  "signature": "sha256:4c3a0c324b35834e9601cdcc8948ef8868b154598a84adbd32748436232235e0"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import sklearn as sk\n",
      "\n",
      "from sklearn.feature_extraction.text import CountVectorizer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# CountVectorizer\n",
      "\n",
      "...compte le nombre d'instances de mots.  La repr\u00e9sentation dense nous montre le vecteur de crit\u00e8res correspondant \u00e0 chaque phrase dans `corpus`.  Sinon, la repr\u00e9sentation est creuse.\n",
      "\n",
      "Essaiez avec le corpus entier pour voir ce que donne un document plus important.\n",
      "\n",
      "\u00c0 essayer et expliquer :\n",
      "* `corpus_encoded.shape`\n",
      "* `corpus_encoded[0].todense()`\n",
      "* `corpus_encoded[0].data` et `print(corpus_encoded[0])`.\n",
      "* `corpus_encoded.todense()[0]`\n",
      "* `vectorizer.inverse_transform(corpus_encoded.todense()[0])`\n",
      "* `vectorizer.transform('The dog runs quickly towards the cat.')`\n",
      "* `vectorizer.transform(['The dog runs quickly towards the cat.'])`\n",
      "* `vectorizer2 = CountVectorizer(binary=True)`"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "corpus = [\n",
      "    \"Il est nuit. La cabane est pauvre, mais bien close.\",\n",
      "    \"Le logis est plein d'ombre et l'on sent quelque chose\",\n",
      "    \"Qui rayonne \u00e0 travers ce cr\u00e9puscule obscur.\",\n",
      "    \"Des filets de p\u00eacheur sont accroch\u00e9s au mur.\",\n",
      "    \"Au fond, dans l'encoignure o\u00f9 quelque humble vaisselle\",\n",
      "    \"Aux planches d'un bahut vaguement \u00e9tincelle,\",\n",
      "    \"On distingue un grand lit aux longs rideaux tombants.\",\n",
      "    \"Tout pr\u00e8s, un matelas s'\u00e9tend sur de vieux bancs,\",\n",
      "    \"Et cinq petits enfants, nid d'\u00e2mes, y sommeillent\",\n",
      "    \"La haute chemin\u00e9e o\u00f9 quelques flammes veillent\",\n",
      "    \"Rougit le plafond sombre, et, le front sur le lit,\",\n",
      "    \"Une femme \u00e0 genoux prie, et songe, et p\u00e2lit.\",\n",
      "    \"C'est la m\u00e8re. Elle est seule. Et dehors, blanc d'\u00e9cume,\",\n",
      "    \"Au ciel, aux vents, aux rocs, \u00e0 la nuit, \u00e0 la brume,\",\n",
      "    \"Le sinistre oc\u00e9an jette son noir sanglot.\",\n",
      "]\n",
      "corpus = corpus[0:2]\n",
      "vectorizer = CountVectorizer()\n",
      "corpus_encoded = vectorizer.fit_transform(corpus)\n",
      "print(corpus_encoded.todense())\n",
      "print('----------------------------------------------------------------')\n",
      "print(vectorizer.vocabulary_)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[1 1 0 1 2 0 1 1 0 0 1 1 0 0 1 0 0 0]\n",
        " [0 0 1 0 1 1 0 0 1 1 0 0 1 1 0 1 1 1]]\n",
        "----------------------------------------------------------------\n",
        "{u'chose': 2, u'nuit': 11, u'quelque': 16, u'il': 6, u'close': 3, u'et': 5, u'pauvre': 14, u'on': 13, u'est': 4, u'plein': 15, u'mais': 10, u'la': 7, u'cabane': 1, u'logis': 9, u'le': 8, u'bien': 0, u'ombre': 12, u'sent': 17}\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Mots vides\n",
      "\n",
      "Ceci ne marche pas :\n",
      "\n",
      "    vectorizer2 = CountVectorizer(stop_words='francais')\n",
      "\n",
      "D\u00e9couvrez un peu plus.  (Astuce : qu'est-ce qui est l'erreur si tu appelles `fit_transform()`?)\n",
      "\n",
      "# Distance\n",
      "\n",
      "* Les vecteurs et matrices sont creuse.  Pourquoi?\n",
      "* Quel probl\u00e8me aurons-nous avec la distance euclidienne?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics.pairwise import euclidean_distances\n",
      "\n",
      "print(euclidean_distances(corpus_encoded[0], corpus_encoded[1]))\n",
      "print(euclidean_distances(corpus_encoded[0], corpus_encoded[0]))\n",
      "jour = vectorizer.transform(['Il est jour. La cabane est pauvre, mais bien close.'])\n",
      "print(euclidean_distances(corpus_encoded[0], jour))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 4.24264069]]\n",
        "[[ 0.]]\n",
        "[[ 1.]]\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "nltk.download()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "showing info http://nltk.github.com/nltk_data/\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 26,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 26
    }
   ],
   "metadata": {}
  }
 ]
}